# The following file is intended for deployments that are not already
# configured with prometheus. This is a minified version of the config
# from the files present under ./openebs-monitoring/
# 
# Prometheus tunables
apiVersion: v1
kind: ConfigMap
metadata:
  name: openebs-prometheus-tunables
  namespace: openebs
data:
  storage-retention: 24h
---
# Define the openebs prometheus jobs
kind: ConfigMap
metadata:
  name: openebs-prometheus-config
  namespace: openebs
apiVersion: v1
data:
  prometheus.yml: |-
    global:
      external_labels:
        slave: slave1
      scrape_interval: 5s
      evaluation_interval: 5s
    scrape_configs:
    - job_name: 'prometheus'
      scheme: http
      kubernetes_sd_configs:
      - role: pod
      relabel_configs:
      - source_labels: [__meta_kubernetes_pod_label_name]
        regex: openebs-prometheus-server
        action: keep
      - source_labels: [__meta_kubernetes_pod_name]
        action: replace
        target_label: kubernetes_pod_name
    - job_name: 'openebs-volumes'
      scheme: http
      kubernetes_sd_configs:
      - role: pod
      relabel_configs:
      - source_labels: [__meta_kubernetes_pod_label_monitoring]
        regex: volume_exporter_prometheus
        action: keep
      - source_labels: [__meta_kubernetes_pod_name]
        action: replace
        target_label: kubernetes_pod_name
      # Below entry ending with vsm is deprecated and is maintained for
      # backward compatibility purpose.
      - source_labels: [__meta_kubernetes_pod_label_vsm]
        action: replace
        target_label: openebs_pv
      # Below entry is the correct entry. Though the above and below entries
      # are having same target_label as openebs_pv, only one of them will be
      # valid for any release.
      - source_labels: [__meta_kubernetes_pod_label_openebs_io_persistent_volume]
        action: replace
        target_label: openebs_pv
      - source_labels: [__meta_kubernetes_pod_container_port_number]
        action: drop
        regex: '(.*)9501'
      - source_labels: [__meta_kubernetes_pod_container_port_number]
        action: drop
        regex: '(.*)3260'
      - source_labels: [__meta_kubernetes_pod_container_port_number]
        action: drop
        regex: '(.*)80'
    - job_name: 'openebs-pools'
      scheme: http
      kubernetes_sd_configs:
      - role: pod
      relabel_configs:
      - source_labels: [__meta_kubernetes_pod_annotation_openebs_io_monitoring]
        regex: pool_exporter_prometheus
        action: keep
      - source_labels: [__meta_kubernetes_pod_name]
        action: replace
        target_label: kubernetes_pod_name
      - source_labels: [__meta_kubernetes_pod_label_openebs_io_storage_pool_claim]
        action: replace
        target_label: storage_pool_claim
      - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]
        action: replace
        regex: ([^:]+)(?::\d+)?;(\d+)
        replacement: ${1}:${2}
        target_label: __address__
    - job_name: 'node'
      tls_config:
        ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
      bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
      kubernetes_sd_configs:
      - role: node
      relabel_configs:
      - action: labelmap
        regex: __meta_kubernetes_node_label_(.+)
      - source_labels: [__meta_kubernetes_role]
        action: replace
        target_label: kubernetes_role
      - source_labels: [__address__]
        regex: '(.*):10250'
        replacement: '${1}:9100'
        target_label: __address__
      - source_labels: [__meta_kubernetes_node_label_kubernetes_io_hostname]
        target_label: __instance__
      - source_labels: [job]
        regex: 'kubernetes-(.*)'
        replacement: '${1}'
        target_label: name
    - job_name: 'mysqld'
      tls_config:
        ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
      bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
      kubernetes_sd_configs:
      - role: pod
      relabel_configs:
      - source_labels: [__meta_kubernetes_pod_label_app]
        regex: prometheus-mysql-exporter
        action: keep
---
# prometheus-deployment
apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: openebs-prometheus
  namespace: openebs
spec:
  replicas: 1
  template:
    metadata:
      labels:
        name: openebs-prometheus-server
    spec:
      serviceAccountName: openebs-maya-operator
      containers:
        - name: prometheus
          image: prom/prometheus:v2.3.0
          args:
            - "--config.file=/etc/prometheus/conf/prometheus.yml"
            # Metrics are stored in an emptyDir volume which
            # exists as long as the Pod is running on that Node.
            # The data in an emptyDir volume is safe across container crashes.
            - "--storage.tsdb.path=/prometheus"
            # How long to retain samples in the local storage.
            - "--storage.tsdb.retention=$(STORAGE_RETENTION)"
          ports:
            - containerPort: 9090
          env:
            # environment vars are stored in prometheus-env configmap. 
            - name: STORAGE_RETENTION
              valueFrom:
                configMapKeyRef:
                  name: openebs-prometheus-tunables
                  key: storage-retention
          resources:
            requests:
              # A memory request of 250M means it will try to ensure minimum
              # 250MB RAM .
              memory: "128M"
              # A cpu request of 128m means it will try to ensure minimum
              # .125 CPU; where 1 CPU means :
              # 1 *Hyperthread* on a bare-metal Intel processor with Hyperthreading
              cpu: "128m"
            limits:
              memory: "700M"
              cpu: "500m"
          
          volumeMounts:
            # prometheus config file stored in the given mountpath
            - name: prometheus-server-volume
              mountPath: /etc/prometheus/conf
            # metrics collected by prometheus will be stored at the given mountpath.
            - name: prometheus-storage-volume
              mountPath: /prometheus
      volumes:
        # Prometheus Config file will be stored in this volume 
        - name: prometheus-server-volume
          configMap:
            name: openebs-prometheus-config
        # All the time series stored in this volume in form of .db file.
        - name: prometheus-storage-volume
          # containers in the Pod can all read and write the same files here.
          emptyDir: {} 
---
# prometheus-service
apiVersion: v1
kind: Service
metadata:
  name: openebs-prometheus-service
  namespace: openebs
spec:
  selector: 
    name: openebs-prometheus-server
  type: NodePort
  ports:
    - port: 80 # this Service's port (cluster-internal IP clusterIP)
      targetPort: 9090 # pods expose this port
      nodePort: 32514
      # Note that this Service will be visible as both NodeIP:nodePort and clusterIp:Port
---
apiVersion: v1
kind: Service
metadata:
  name: openebs-grafana
  namespace: openebs
spec:
  type: NodePort
  ports:
  - port: 3000
    targetPort: 3000
    nodePort: 32515
  selector:
    app: openebs-grafana
---
apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  labels:
    app: openebs-grafana
  name: openebs-grafana
  namespace: openebs
spec:
  replicas: 1
  revisionHistoryLimit: 2
  template:
    metadata:
      labels:
        app: openebs-grafana
    spec:
      containers:
      - image: grafana/grafana:5.2.0
        name: grafana
        ports:
        - containerPort: 3000
        env:
          - name: GF_AUTH_BASIC_ENABLED
            value: "true"
          - name: GF_AUTH_ANONYMOUS_ENABLED
            value: "false"
        livenessProbe:
          httpGet:
            path: /
            port: 3000
          initialDelaySeconds: 30
          timeoutSeconds: 1
---
# node-exporter will be launch as daemonset.
apiVersion: extensions/v1beta1
kind: DaemonSet
metadata:
  name: node-exporter
  namespace: openebs
spec:
  template:
    metadata:
      labels:
        app: node-exporter
      name: node-exporter
    spec:
      containers:
      - image: prom/node-exporter:v0.16.0
        name: node-exporter
        ports:
        - containerPort: 9100
          hostPort: 9100
          name: scrape
        resources:
            requests:
              # A memory request of 250M means it will try to ensure minimum
              # 250MB RAM .
              memory: "128M"
              # A cpu request of 128m means it will try to ensure minimum
              # .125 CPU; where 1 CPU means :
              # 1 *Hyperthread* on a bare-metal Intel processor with Hyperthreading
              cpu: "128m"
            limits:
              memory: "700M"
              cpu: "500m"
        volumeMounts:
        # All the application data stored in data-disk
        - name: data-disk
          mountPath: /data-disk
          readOnly: true
        # Root disk is where OS(Node) is installed
        - name: root-disk
          mountPath: /root-disk
          readOnly: true
      # The Kubernetes scheduler’s default behavior works well for most cases
      # -- for example, it ensures that pods are only placed on nodes that have 
      # sufficient free resources, it ties to spread pods from the same set 
      # (ReplicaSet, StatefulSet, etc.) across nodes, it tries to balance out 
      # the resource utilization of nodes, etc.
      #
      # But sometimes you want to control how your pods are scheduled. For example,
      # perhaps you want to ensure that certain pods only schedule on nodes with 
      # specialized hardware, or you want to co-locate services that communicate 
      # frequently, or you want to dedicate a set of nodes to a particular set of 
      # users. Ultimately, you know much more about how your applications should be
      # scheduled and deployed than Kubernetes ever will.
      #
      # “taints and tolerations,” allows you to mark (“taint”) a node so that no 
      # pods can schedule onto it unless a pod explicitly “tolerates” the taint.
      # toleration  is particularly useful for situations where most pods in 
      # the cluster should avoid scheduling onto the node. In our case we want
      # node-exporter to run on master node also i.e, we want to collect metrics 
      # from master node. That's why tolerations added.
      # if removed master's node metrics can't be scrapped by prometheus.
      tolerations:
      - effect: NoSchedule
        operator: Exists
      volumes:
        # A hostPath volume mounts a file or directory from the host node’s 
        # filesystem.For example, some uses for a hostPath are:
        # running a container that needs access to Docker internals; use a hostPath 
        # of /var/lib/docker
        # running cAdvisor in a container; use a hostPath of /dev/cgroups
        - name: data-disk
          hostPath:
            path: /localdata
        - name: root-disk
          hostPath:
            path: /
      hostNetwork: true
      hostPID: true
